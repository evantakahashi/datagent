# Using the Evaluation System with Real Data

## Understanding the Demo vs Production

### **In the Demo (`demo.py`)**

Both datasets are synthetically generated:
- **"Real/Baseline"** (seed=42): Simulates actual patient records
- **"Synthetic/Test"** (seed=123): Simulates your generated synthetic data
- **Purpose**: Show you how the evaluation framework works

### **In Production (Your Use Case)**

You have two distinct datasets:
- **Real**: Actual patient records from your EHR/database
- **Synthetic**: Data generated by your model/system
- **Purpose**: Evaluate quality of your synthetic data generation

---

## How to Use with Your Real Data

### **Option 1: Load Your Own Patient Records**

```python
from src.evaluators import (
    EmbeddingAnalyzer,
    DistributionMetrics,
    ConceptEntropyCalculator,
    CoverageAnalyzer,
    RedundancyChecker
)
from src.models import PatientRecord

# Load your real patient records
real_records = load_your_ehr_data()  # Your function to load real data

# Load your synthetic patient records
synthetic_records = load_your_synthetic_data()  # Your generated data

# Run evaluation
embedding_analyzer = EmbeddingAnalyzer()
results = embedding_analyzer.analyze_diversity(real_records, synthetic_records)

# Check metrics
print(f"Coverage @ 0.8: {results['coverage_metrics']['coverage@0.8']:.2%}")
print(f"Diversity score: {results['coverage_metrics']['diversity_score']:.3f}")
```

### **Option 2: Convert Your Data to PatientRecord Format**

If your data is in a different format (JSON, CSV, database), convert it:

```python
from src.models import PatientRecord, Demographics, VitalSigns, Sex, Ethnicity
from datetime import datetime, date

def convert_your_data_to_patient_record(your_record):
    """Convert your data format to PatientRecord"""

    # Create demographics
    demographics = Demographics(
        age=your_record['age'],
        sex=Sex(your_record['sex']),  # 'male', 'female', 'other'
        ethnicity=Ethnicity(your_record['ethnicity']),
        location=your_record['location']
    )

    # Create vitals
    vitals = VitalSigns(
        heart_rate=your_record['vitals']['hr'],
        systolic_bp=your_record['vitals']['sbp'],
        diastolic_bp=your_record['vitals']['dbp'],
        temperature=your_record['vitals']['temp'],
        respiratory_rate=your_record['vitals']['rr'],
        oxygen_saturation=your_record['vitals']['spo2']
    )

    # Create conditions
    conditions = []
    for cond in your_record['conditions']:
        conditions.append(Condition(
            name=cond['name'],
            icd10_code=cond['icd10'],
            onset_date=date.fromisoformat(cond['onset']),
            severity=cond['severity'],  # 'mild', 'moderate', 'severe'
            status=cond['status']  # 'active', 'resolved', 'chronic'
        ))

    # Create medications (similar pattern)
    medications = [...]

    # Create lab results (similar pattern)
    lab_results = [...]

    # Assemble full record
    return PatientRecord(
        record_id=your_record['id'],
        demographics=demographics,
        chief_complaint=your_record['complaint'],
        vitals=vitals,
        conditions=conditions,
        medications=medications,
        lab_results=lab_results,
        clinical_notes=your_record['notes'],
        visit_date=datetime.fromisoformat(your_record['visit_date'])
    )

# Convert all your records
real_records = [convert_your_data_to_patient_record(r) for r in your_real_data]
synthetic_records = [convert_your_data_to_patient_record(r) for r in your_synthetic_data]

# Now run evaluation
```

### **Option 3: Evaluate Only Synthetic Data (No Real Baseline)**

If you don't have real data but want to check quality of your synthetic data:

```python
from src.evaluators import CoverageAnalyzer, RedundancyChecker, ConceptEntropyCalculator

# Load your synthetic data
synthetic_records = load_your_synthetic_data()

# Check for redundancy
redundancy_checker = RedundancyChecker()
redundancy = redundancy_checker.analyze_redundancy(synthetic_records)
print(f"Near-duplicates: {redundancy['n_near_duplicate_pairs']}")

# Check coverage (balance across dimensions)
coverage_analyzer = CoverageAnalyzer()
coverage = coverage_analyzer.analyze_coverage(synthetic_records)
print(f"Coverage score: {coverage['overall_coverage_score']:.3f}")
print(f"Gaps: {coverage['gaps']}")

# Check entropy (balance)
entropy_calc = ConceptEntropyCalculator()
entropy = entropy_calc.calculate_concept_entropy_metrics(synthetic_records)
print(f"Diversity score: {entropy['overall_diversity_score']:.3f}")

# Remove duplicates if found
if redundancy['n_near_duplicate_pairs'] > 0:
    clean_records, _, stats = redundancy_checker.deduplicate(synthetic_records)
    print(f"Removed {stats['n_removed']} redundant records")
```

---

## Example: Loading from JSON

```python
import json
from datetime import datetime, date

def load_patient_records_from_json(filepath):
    """Load patient records from JSON file"""
    with open(filepath, 'r') as f:
        data = json.load(f)

    records = []
    for record_data in data:
        # Convert JSON to PatientRecord
        demographics = Demographics(
            age=record_data['demographics']['age'],
            sex=Sex(record_data['demographics']['sex']),
            ethnicity=Ethnicity(record_data['demographics']['ethnicity']),
            location=record_data['demographics']['location']
        )

        vitals = VitalSigns(**record_data['vitals'])

        conditions = [
            Condition(
                name=c['name'],
                icd10_code=c['icd10_code'],
                onset_date=date.fromisoformat(c['onset_date']),
                severity=c['severity'],
                status=c['status']
            )
            for c in record_data['conditions']
        ]

        medications = [
            Medication(
                name=m['name'],
                dosage=m['dosage'],
                frequency=m['frequency'],
                indication=m['indication'],
                start_date=date.fromisoformat(m['start_date'])
            )
            for m in record_data['medications']
        ]

        lab_results = [
            LabResult(**lab)
            for lab in record_data['lab_results']
        ]

        record = PatientRecord(
            record_id=record_data['record_id'],
            demographics=demographics,
            chief_complaint=record_data['chief_complaint'],
            vitals=vitals,
            conditions=conditions,
            medications=medications,
            lab_results=lab_results,
            clinical_notes=record_data['clinical_notes'],
            visit_date=datetime.fromisoformat(record_data['visit_date'])
        )

        records.append(record)

    return records

# Usage
real_records = load_patient_records_from_json('real_patient_data.json')
synthetic_records = load_patient_records_from_json('synthetic_patient_data.json')

# Evaluate
from src.evaluators import EmbeddingAnalyzer

analyzer = EmbeddingAnalyzer()
results = analyzer.analyze_diversity(real_records, synthetic_records)
```

---

## Example: Loading from CSV/Database

```python
import pandas as pd

def load_from_csv(filepath):
    """Load patient records from CSV"""
    df = pd.read_csv(filepath)

    records = []
    for _, row in df.iterrows():
        # Parse conditions (stored as JSON string in CSV)
        conditions_data = json.loads(row['conditions'])
        conditions = [
            Condition(
                name=c['name'],
                icd10_code=c['icd10_code'],
                onset_date=date.fromisoformat(c['onset_date']),
                severity=c['severity'],
                status=c['status']
            )
            for c in conditions_data
        ]

        # Build record
        demographics = Demographics(
            age=int(row['age']),
            sex=Sex(row['sex']),
            ethnicity=Ethnicity(row['ethnicity']),
            location=row['location']
        )

        vitals = VitalSigns(
            heart_rate=float(row['heart_rate']),
            systolic_bp=float(row['systolic_bp']),
            diastolic_bp=float(row['diastolic_bp']),
            temperature=float(row['temperature']),
            respiratory_rate=float(row['respiratory_rate']),
            oxygen_saturation=float(row['oxygen_saturation'])
        )

        # ... build medications, labs similarly

        record = PatientRecord(
            record_id=row['record_id'],
            demographics=demographics,
            chief_complaint=row['chief_complaint'],
            vitals=vitals,
            conditions=conditions,
            medications=[],  # Parse from CSV
            lab_results=[],  # Parse from CSV
            clinical_notes=row['clinical_notes'],
            visit_date=datetime.fromisoformat(row['visit_date'])
        )

        records.append(record)

    return records
```

---

## Complete Production Example

```python
from src.evaluators import (
    EmbeddingAnalyzer,
    DistributionMetrics,
    ConceptEntropyCalculator,
    RedundancyChecker,
    CoverageAnalyzer,
    DiversityVisualizer
)
from src.utils import ReportGenerator

# 1. Load your data
real_records = load_your_ehr_data()  # Your actual patient records
synthetic_records = load_your_generated_data()  # Your synthetic data

# 2. Run all evaluations
print("Analyzing with ClinicalBERT...")
embedding_analyzer = EmbeddingAnalyzer()
embedding_results = embedding_analyzer.analyze_diversity(real_records, synthetic_records)

print("Computing distribution metrics...")
dist_calculator = DistributionMetrics()
distribution_metrics = dist_calculator.compute_distribution_metrics(
    real_records,
    synthetic_records,
    embedding_results['real_embeddings'],
    embedding_results['synthetic_embeddings']
)

print("Calculating entropy...")
entropy_calc = ConceptEntropyCalculator()
entropy_comparison = entropy_calc.compare_entropy(real_records, synthetic_records)

# 3. Generate visualizations
visualizer = DiversityVisualizer(output_dir="production_results")
visualizer.plot_tsne(
    embedding_results['real_embeddings'],
    embedding_results['synthetic_embeddings']
)
visualizer.plot_distribution_comparison(real_records, synthetic_records)
visualizer.plot_entropy_comparison(entropy_comparison)

# 4. Generate reports
report_generator = ReportGenerator()
results = {
    'dataset_info': {
        'n_real': len(real_records),
        'n_synthetic': len(synthetic_records),
        'timestamp': datetime.now().isoformat(),
    },
    'embedding_metrics': embedding_results,
    'distribution_metrics': distribution_metrics,
    'entropy_comparison': entropy_comparison,
}

report_generator.generate_text_report(results, "production_results/evaluation_report.txt")
report_generator.save_json_report(results, "production_results/evaluation_report.json")

print("Evaluation complete! Check production_results/ for outputs.")
```

---

## Key Metrics to Monitor in Production

### **Quality Thresholds**

| Metric | Good | Acceptable | Poor |
|--------|------|------------|------|
| Coverage @ 0.8 | > 70% | 50-70% | < 50% |
| Diversity Score | > 0.75 | 0.6-0.75 | < 0.6 |
| FID Score | < 50 | 50-100 | > 100 |
| KL Divergence (avg) | < 0.1 | 0.1-0.3 | > 0.3 |
| Coverage Score | > 0.8 | 0.6-0.8 | < 0.6 |

### **Red Flags**

- **FID > 100**: Synthetic data significantly differs from real
- **Coverage @ 0.8 < 50%**: Many synthetic records don't match real patterns
- **Coverage gaps > 3**: Missing key demographic/clinical groups
- **Diversity score < 0.6**: Unbalanced, concentrated distribution

---

## Summary

**Demo (`demo.py`)**: Both datasets synthetic → Shows HOW to evaluate

**Production (Your Use Case)**: Real vs Synthetic → Shows QUALITY of your data

Use the same evaluation code, just load your actual data instead of generating both synthetically!
