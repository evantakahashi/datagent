"""
Demo script for Synthetic Medical Data Evaluation Agent

This demonstrates:
1. Generating synthetic patient records with medical constraints
2. Analyzing diversity using ClinicalBERT embeddings
3. Computing distribution metrics (KL-divergence, FID)
4. Calculating concept entropy
5. Creating visualizations (t-SNE, distributions)
6. Generating comprehensive reports
"""

import os
import sys
import numpy as np
from datetime import datetime

# Add src to path
sys.path.insert(0, os.path.dirname(__file__))

from src.generators import PatientRecordGenerator
from src.evaluators import (
    EmbeddingAnalyzer,
    DistributionMetrics,
    ConceptEntropyCalculator,
    DiversityVisualizer
)
from src.utils import ReportGenerator


def main():
    """Run the complete demo"""
    print("=" * 80)
    print("SYNTHETIC MEDICAL DATA EVALUATION AGENT - DEMO")
    print("=" * 80)
    print()
    print("This demo shows HOW to evaluate synthetic medical data quality.")
    print()
    print("IMPORTANT NOTE:")
    print("  - 'Real/Baseline' records: Simulated with seed=42 (in production: actual EHR data)")
    print("  - 'Synthetic/Test' records: Simulated with seed=123 (in production: your generated data)")
    print("  - Both are synthetic in this demo to show the evaluation framework")
    print()
    print("The metrics show you how well the 'test' data matches the 'baseline' distribution.")
    print("=" * 80)
    print()

    # Configuration
    N_REAL = 50  # Number of "real" records to simulate
    N_SYNTHETIC = 50  # Number of synthetic records to generate
    OUTPUT_DIR = "outputs"
    USE_CLINICALBERT = True  # Set to False to skip embedding analysis (faster demo)

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # =========================================================================
    # STEP 1: Generate "Real" Patient Records
    # =========================================================================
    print("STEP 1: Generating 'real' patient records (simulated baseline)...")
    print("-" * 80)
    print("NOTE: In a real use case, these would be actual patient records from your EHR.")
    print("      For this demo, we generate them synthetically to simulate a baseline dataset.")
    print()

    # In a real scenario, these would be actual patient records
    # For demo, we generate with constraints to simulate a real distribution
    real_generator = PatientRecordGenerator(seed=42)
    real_records = real_generator.generate_batch(N_REAL, diversity_constraints=True)

    print(f"Generated {len(real_records)} baseline patient records")
    print(f"Example record: {real_records[0].record_id}")
    print(f"  Age: {real_records[0].demographics.age}, Sex: {real_records[0].demographics.sex.value}")
    print(f"  Conditions: {[c.name for c in real_records[0].conditions]}")
    print()

    # Save a sample record as text
    sample_path = os.path.join(OUTPUT_DIR, "sample_patient_record.txt")
    with open(sample_path, 'w') as f:
        f.write(real_records[0].to_text())
    print(f"Sample patient record saved to {sample_path}")
    print()

    # =========================================================================
    # STEP 2: Generate Synthetic Patient Records (Test Set)
    # =========================================================================
    print("\nSTEP 2: Generating synthetic patient records (test set)...")
    print("-" * 80)
    print("NOTE: This simulates synthetic data generated by your model/system.")
    print("      We'll evaluate how well it matches the baseline distribution.")
    print()

    synthetic_generator = PatientRecordGenerator(seed=123)  # Different seed
    synthetic_records = synthetic_generator.generate_batch(N_SYNTHETIC, diversity_constraints=True)

    print(f"Generated {len(synthetic_records)} test synthetic patient records")
    print()

    # =========================================================================
    # STEP 3: Embedding Coverage Analysis (ClinicalBERT)
    # =========================================================================
    embedding_results = None
    if USE_CLINICALBERT:
        print("STEP 3: Analyzing embedding coverage with ClinicalBERT...")
        print("-" * 80)
        print("Note: First run will download the ClinicalBERT model (~400MB)")
        print()

        try:
            embedding_analyzer = EmbeddingAnalyzer()
            embedding_results = embedding_analyzer.analyze_diversity(real_records, synthetic_records)

            print("\nEmbedding Coverage Metrics:")
            for key, value in embedding_results['coverage_metrics'].items():
                print(f"  {key}: {value:.4f}")
            print()

        except Exception as e:
            print(f"Warning: Could not run embedding analysis: {e}")
            print("Continuing with other metrics...")
            USE_CLINICALBERT = False
            print()
    else:
        print("STEP 3: Skipping embedding analysis (disabled)")
        print()

    # =========================================================================
    # STEP 4: Distribution Metrics (KL-divergence, FID)
    # =========================================================================
    print("STEP 4: Computing distribution metrics...")
    print("-" * 80)

    dist_calculator = DistributionMetrics()

    if USE_CLINICALBERT and embedding_results:
        distribution_metrics = dist_calculator.compute_distribution_metrics(
            real_records,
            synthetic_records,
            embedding_results['real_embeddings'],
            embedding_results['synthetic_embeddings']
        )
    else:
        # Create dummy embeddings for demo if ClinicalBERT not available
        print("Creating dummy embeddings for distribution metrics...")
        real_embeddings = np.random.randn(N_REAL, 128)
        synthetic_embeddings = np.random.randn(N_SYNTHETIC, 128)
        distribution_metrics = dist_calculator.compute_distribution_metrics(
            real_records,
            synthetic_records,
            real_embeddings,
            synthetic_embeddings
        )

    print("\nDistribution Metrics:")
    print(f"  FID Score: {distribution_metrics['fid_score']:.4f}")
    print(f"  Average KL Divergence: {distribution_metrics['kl_div_average']:.4f}")
    print()

    # =========================================================================
    # STEP 5: Concept Entropy Analysis
    # =========================================================================
    print("STEP 5: Calculating concept entropy...")
    print("-" * 80)

    entropy_calculator = ConceptEntropyCalculator()
    entropy_comparison = entropy_calculator.compare_entropy(real_records, synthetic_records)

    print("\nConcept Entropy Metrics:")
    print(f"  Real Diversity Score: {entropy_comparison['real_diversity_score']:.4f}")
    print(f"  Synthetic Diversity Score: {entropy_comparison['synthetic_diversity_score']:.4f}")
    print(f"  Difference: {entropy_comparison['diversity_score_diff']:.4f}")
    print()

    # =========================================================================
    # STEP 6: Generate Visualizations
    # =========================================================================
    print("STEP 6: Creating visualizations...")
    print("-" * 80)

    visualizer = DiversityVisualizer(output_dir=OUTPUT_DIR)

    # t-SNE visualization
    if USE_CLINICALBERT and embedding_results:
        visualizer.plot_tsne(
            embedding_results['real_embeddings'],
            embedding_results['synthetic_embeddings']
        )

    # Distribution comparisons
    visualizer.plot_distribution_comparison(real_records, synthetic_records)

    # Entropy comparison
    visualizer.plot_entropy_comparison(entropy_comparison)

    # Metrics summary
    summary_metrics = {
        'Diversity Score': entropy_comparison['synthetic_diversity_score'],
        'Embedding Coverage': embedding_results['coverage_metrics']['coverage@0.8'] if embedding_results else 0.0,
    }
    visualizer.plot_metrics_summary(summary_metrics)

    print()

    # =========================================================================
    # STEP 7: Generate Reports
    # =========================================================================
    print("STEP 7: Generating reports...")
    print("-" * 80)

    # Compile all results
    results = {
        'dataset_info': {
            'n_real': N_REAL,
            'n_synthetic': N_SYNTHETIC,
            'timestamp': datetime.now().isoformat(),
        },
        'embedding_metrics': embedding_results if embedding_results else None,
        'distribution_metrics': distribution_metrics,
        'entropy_comparison': entropy_comparison,
    }

    # Generate text report
    report_generator = ReportGenerator()
    text_report_path = os.path.join(OUTPUT_DIR, "evaluation_report.txt")
    report_text = report_generator.generate_text_report(results, text_report_path)

    # Generate JSON report
    json_report_path = os.path.join(OUTPUT_DIR, "evaluation_report.json")
    report_generator.save_json_report(results, json_report_path)

    print()

    # =========================================================================
    # Summary
    # =========================================================================
    print("=" * 80)
    print("DEMO COMPLETE!")
    print("=" * 80)
    print()
    print("Generated outputs:")
    print(f"  - Sample patient record: {sample_path}")
    print(f"  - Text report: {text_report_path}")
    print(f"  - JSON report: {json_report_path}")
    if USE_CLINICALBERT:
        print(f"  - t-SNE visualization: {os.path.join(OUTPUT_DIR, 'tsne_visualization.png')}")
    print(f"  - Distribution comparison: {os.path.join(OUTPUT_DIR, 'distribution_comparison.png')}")
    print(f"  - Entropy comparison: {os.path.join(OUTPUT_DIR, 'entropy_comparison.png')}")
    print(f"  - Metrics summary: {os.path.join(OUTPUT_DIR, 'metrics_summary.png')}")
    print()
    print("Review the text report for a summary of diversity metrics!")
    print()

    # Print the text report
    print("=" * 80)
    print("TEXT REPORT PREVIEW")
    print("=" * 80)
    print(report_text)


if __name__ == "__main__":
    main()
